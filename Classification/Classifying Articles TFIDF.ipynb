{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing in the data\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "files = glob.glob(\"/home/mazz76/jupyter/Civic_Info_Project/Category_Classification_Data/*.csv\")\n",
    "\n",
    "df = []\n",
    "for f in files:\n",
    "    csv = pd.read_csv(f)\n",
    "    df.append(csv)\n",
    "df = pd.concat(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sports        266\n",
       "civic life    262\n",
       "crime         243\n",
       "road          137\n",
       "health         48\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove NaN\n",
    "\n",
    "#df \n",
    "#df2=df.dropna().reset_index(drop=True)\n",
    "#df2\n",
    "#df2.category.value_counts()\n",
    "\n",
    "df = df.loc[df['category'] != 'raod']\n",
    "df = df.loc[df['category'] != 'cime']\n",
    "df = df.loc[df['category'] != 'other']\n",
    "df = df.replace(to_replace=\"roads\",\n",
    "           value=\"road\")\n",
    "df = df.replace(to_replace=\"civic\",\n",
    "           value=\"civic life\")\n",
    "df2 = df \n",
    "df2.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import re \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import pandas as pd \n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16246</th>\n",
       "      <td>police department</td>\n",
       "      <td>3.599652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16332</th>\n",
       "      <td>police said</td>\n",
       "      <td>3.192132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>county police</td>\n",
       "      <td>2.446582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16142</th>\n",
       "      <td>pleaded guilty</td>\n",
       "      <td>2.422689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16334</th>\n",
       "      <td>police say</td>\n",
       "      <td>2.266769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16628</th>\n",
       "      <td>probable cause</td>\n",
       "      <td>2.205424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>first degree</td>\n",
       "      <td>2.024870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8873</th>\n",
       "      <td>gas station</td>\n",
       "      <td>1.982183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362</th>\n",
       "      <td>court documents</td>\n",
       "      <td>1.895570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9556</th>\n",
       "      <td>gunshot wound</td>\n",
       "      <td>1.886421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    term      rank\n",
       "16246  police department  3.599652\n",
       "16332        police said  3.192132\n",
       "5286       county police  2.446582\n",
       "16142     pleaded guilty  2.422689\n",
       "16334         police say  2.266769\n",
       "16628     probable cause  2.205424\n",
       "8351        first degree  2.024870\n",
       "8873         gas station  1.982183\n",
       "5362     court documents  1.895570\n",
       "9556       gunshot wound  1.886421"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crime data bigrams\n",
    "crime = df2.loc[df2['category'] == 'crime']\n",
    "\n",
    "crime_document_list = []\n",
    "for x in crime['text']:\n",
    "    if x not in crime_document_list:\n",
    "        crime_document_list.append(x)\n",
    "    \n",
    "#Removing stopwords\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "more_stop_words = ['st.', 'louis', 'kansas', 'p.','m.', 'kmov', 'reserved', 'mo', 'news',\n",
    "                    'correction','typo','email','ky3', 'comcopyright', 'digitalnews', 'fox',\n",
    "                    'springfield', '2022', 'jasper','metropolitan', 'please', 'crimestoppers', 'copyright', 'year',\n",
    "                  'old','tips','hotline']\n",
    "\n",
    "for i, line in enumerate(crime_document_list): \n",
    "    crime_document_list[i] = ' '.join([x for x in nltk.word_tokenize(line) if (x.lower() not in stop_words) and (x.lower() not in more_stop_words)\n",
    "                                      and not (x.lower().isdigit())])\n",
    "    \n",
    "\n",
    "#Getting trigrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (2,2)) \n",
    "X1 = vectorizer.fit_transform(crime_document_list)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "#print(\"\\n\\nFeatures : \\n\", features) \n",
    "#print(\"\\n\\nX1 : \\n\", X1.toarray()) \n",
    "\n",
    "#Applying TFIDF \n",
    "vectorizer = TfidfVectorizer(ngram_range = (2,2)) \n",
    "X2 = vectorizer.fit_transform(crime_document_list) \n",
    "scores = (X2.toarray()) \n",
    "#print(\"\\n\\nScores : \\n\", scores) \n",
    "\n",
    "# Getting the trigrams \n",
    "\n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "\n",
    "for col, term in enumerate(features): \n",
    "    data1.append((term, sums[0,col])) \n",
    "\n",
    "crime_bigrams = pd.DataFrame(data1, columns = ['term','rank']) \n",
    "\n",
    "crime_bigrams = crime_bigrams.sort_values('rank', ascending=False)\n",
    "crime_bigrams = crime_bigrams[crime_bigrams['term'].str.contains('year|maryland|independence')==False ]\n",
    "crime_bigrams.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "county circuit court\n",
      "armed criminal action\n",
      "county police department\n",
      "probable cause affidavit\n",
      "year old man\n",
      "according probable cause\n",
      "pronounced dead scene\n",
      "information becomes available\n",
      "866 371 tips\n",
      "first degree murder\n"
     ]
    }
   ],
   "source": [
    "#Crime data trigrams\n",
    "crime = df2.loc[df2['category'] == 'crime']\n",
    "\n",
    "crime_document_list = []\n",
    "for x in crime['text']:\n",
    "    if x not in crime_document_list:\n",
    "        crime_document_list.append(x)\n",
    "    \n",
    "#Removing stopwords\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "more_stop_words = ['st.', 'louis', 'kansas', 'p.','m.', 'kmov', 'reserved', 'mo', 'news',\n",
    "                    'correction','typo','email','ky3', 'comcopyright', 'digitalnews', 'fox',\n",
    "                    'springfield', '2022', 'jasper','metropolitan', 'please', 'crimestoppers', 'copyright', 'year',\n",
    "                  'old','tips','hotline']\n",
    "\n",
    "for i, line in enumerate(crime_document_list): \n",
    "    crime_document_list[i] = ' '.join([x for x in nltk.word_tokenize(line) if (x.lower() not in stop_words) and (x.lower() not in more_stop_words)\n",
    "                                      and not (x.lower().isdigit())])\n",
    "    \n",
    "\n",
    "#Getting trigrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (3,3)) \n",
    "X1 = vectorizer.fit_transform(crime_document_list)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "#print(\"\\n\\nFeatures : \\n\", features) \n",
    "#print(\"\\n\\nX1 : \\n\", X1.toarray()) \n",
    "\n",
    "#Applying TFIDF \n",
    "vectorizer = TfidfVectorizer(ngram_range = (3,3)) \n",
    "X2 = vectorizer.fit_transform(crime_document_list) \n",
    "scores = (X2.toarray()) \n",
    "#print(\"\\n\\nScores : \\n\", scores) \n",
    "\n",
    "# Getting the trigrams \n",
    "\n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "\n",
    "for col, term in enumerate(features): \n",
    "    data1.append((term, sums[0,col])) \n",
    "\n",
    "crime_trigrams = pd.DataFrame(data1, columns = ['term','rank']) \n",
    "\n",
    "crime_trigrams = crime_trigrams.sort_values('rank', ascending=False)\n",
    "crime_trigrams.head(60)\n",
    "\n",
    "for x in crime_trigrams['term'].head(10):\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sports Stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15506</th>\n",
       "      <td>first half</td>\n",
       "      <td>2.811606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>high school</td>\n",
       "      <td>2.553338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16441</th>\n",
       "      <td>fourth quarter</td>\n",
       "      <td>2.431456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37354</th>\n",
       "      <td>second half</td>\n",
       "      <td>2.353917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15550</th>\n",
       "      <td>first quarter</td>\n",
       "      <td>2.299212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40125</th>\n",
       "      <td>state title</td>\n",
       "      <td>0.587981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8024</th>\n",
       "      <td>career high</td>\n",
       "      <td>0.586589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>blaine salsman</td>\n",
       "      <td>0.583614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26542</th>\n",
       "      <td>men basketball</td>\n",
       "      <td>0.583003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29393</th>\n",
       "      <td>opening round</td>\n",
       "      <td>0.582504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 term      rank\n",
       "15506      first half  2.811606\n",
       "20155     high school  2.553338\n",
       "16441  fourth quarter  2.431456\n",
       "37354     second half  2.353917\n",
       "15550   first quarter  2.299212\n",
       "...               ...       ...\n",
       "40125     state title  0.587981\n",
       "8024      career high  0.586589\n",
       "6447   blaine salsman  0.583614\n",
       "26542  men basketball  0.583003\n",
       "29393   opening round  0.582504\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = df2.loc[df2['category'] == 'sports']\n",
    "\n",
    "sports_document_list = []\n",
    "for x in sports['text']:\n",
    "    if x not in sports_document_list:\n",
    "        sports_document_list.append(x)\n",
    "    \n",
    "#Removing stopwords\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "more_stop_words = ['st.', 'louis', 'kansas', 'p.','m.', 'kmov', 'reserved', 'mo', 'news',\n",
    "                                                                  'correction','typo','email','ky3', 'comcopyright', 'digitalnews', 'fox',\n",
    "                                                                  'springfield', '2022', 'said', 'lady','mizzou','blair', 'missouri','blue','gold',\n",
    "                                                                  'west','webb','pink','carl','southern','news-leader','wheeler','newton','buchanan',\n",
    "                  'jefferson','county','bobby','reeds','logan','sparta']\n",
    "\n",
    "for i, line in enumerate(sports_document_list): \n",
    "    sports_document_list[i] = ' '.join([x for x in nltk.word_tokenize(line) if (x.lower() not in stop_words) and (x.lower() not in more_stop_words)\n",
    "                                      and not (x.lower().isdigit())])\n",
    "    \n",
    "\n",
    "#Getting bigrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (2,2)) \n",
    "X1 = vectorizer.fit_transform(sports_document_list)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "#print(\"\\n\\nFeatures : \\n\", features) \n",
    "#print(\"\\n\\nX1 : \\n\", X1.toarray()) \n",
    "\n",
    "#Applying TFIDF \n",
    "vectorizer = TfidfVectorizer(ngram_range = (2,2)) \n",
    "X2 = vectorizer.fit_transform(sports_document_list) \n",
    "scores = (X2.toarray()) \n",
    "#print(\"\\n\\nScores : \\n\", scores) \n",
    "\n",
    "# Getting the bigrams \n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "\n",
    "for col, term in enumerate(features): \n",
    "    data1.append((term, sums[0,col])) \n",
    "\n",
    "sports_bigrams = pd.DataFrame(data1, columns = ['term','rank']) \n",
    "\n",
    "sports_bigrams = sports_bigrams.sort_values('rank', ascending=False)\n",
    "sports_bigrams = sports_bigrams[sports_bigrams['term'].str.contains('fixed|slot|admanager|region|ad|tncms|logan')==False ]\n",
    "sports_bigrams.head(150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free throw line\n",
      "boys basketball team\n",
      "game high points\n",
      "girls basketball team\n",
      "score double figures\n",
      "two free throws\n",
      "high school football\n",
      "points per game\n",
      "third place game\n",
      "seventh place game\n"
     ]
    }
   ],
   "source": [
    "#Removing stopwords\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "more_stop_words = ['st.', 'louis', 'kansas', 'p.','m.', 'kmov', 'reserved', 'mo', 'news',\n",
    "                                                                  'correction','typo','email','ky3', 'comcopyright', 'digitalnews', 'fox',\n",
    "                                                                  'springfield', '2022', 'said', 'lady','mizzou','blair', 'missouri','blue','gold',\n",
    "                                                                  'west','webb','pink','carl','southern','news-leader','wheeler', 'reporter',\n",
    "                                                                  'columnist','twitter','com', 'wwheeler', 'contact', 'wyattwheeler_nl', \"'s\",\n",
    "                                                                  'd.','co-host', 'also','talk','radio', 'jock', 'osage','camdenton','417-371-6987',\n",
    "                                                                  'macks','admanager','render','region','asset','fixed','tncms','slot','ad','fold','fixed','big']\n",
    "\n",
    "for i, line in enumerate(sports_document_list): \n",
    "    sports_document_list[i] = ' '.join([x for x in nltk.word_tokenize(line) if (x.lower() not in stop_words) and (x.lower() not in more_stop_words)\n",
    "                                      and not (x.lower().isdigit())])\n",
    "    \n",
    "\n",
    "#Getting trigrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (3,3)) \n",
    "X1 = vectorizer.fit_transform(sports_document_list)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "#print(\"\\n\\nFeatures : \\n\", features) \n",
    "#print(\"\\n\\nX1 : \\n\", X1.toarray()) \n",
    "\n",
    "#Applying TFIDF \n",
    "vectorizer = TfidfVectorizer(ngram_range = (3,3)) \n",
    "X2 = vectorizer.fit_transform(sports_document_list) \n",
    "scores = (X2.toarray()) \n",
    "#print(\"\\n\\nScores : \\n\", scores) \n",
    "\n",
    "#Getting the trigrams \n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "\n",
    "for col, term in enumerate(features): \n",
    "    data1.append((term, sums[0,col])) \n",
    "\n",
    "sports_trigrams = pd.DataFrame(data1, columns = ['term','rank']) \n",
    "\n",
    "sports_trigrams = sports_trigrams.sort_values('rank', ascending=False)\n",
    "sports_trigrams = sports_trigrams[sports_trigrams['term'].str.contains('great|asset|rolla|fixed|slot|admanager|region|ad|tncms|logan')==False ]\n",
    "sports_trigrams.head(40)\n",
    "\n",
    "for x in sports_trigrams['term'].head(10):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Civic Life Stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city council\n",
      "school district\n",
      "school board\n",
      "sales tax\n",
      "board aldermen\n",
      "city hall\n",
      "four day\n",
      "public hearing\n",
      "board education\n",
      "planning zoning\n"
     ]
    }
   ],
   "source": [
    "civic = df2.loc[df2['category'] == 'civic life']\n",
    "\n",
    "civic_document_list = []\n",
    "for x in civic['text']:\n",
    "    if x not in civic_document_list:\n",
    "        civic_document_list.append(x)\n",
    "    \n",
    "#Removing stopwords\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "more_stop_words = ['st.', 'louis', 'kansas', 'p.','m.', 'kmov', 'reserved', 'mo', 'news',\n",
    "                                                                  'correction','typo','email','ky3', 'comcopyright', 'digitalnews', 'fox',\n",
    "                                                                  'springfield', '2022', 'said', 'lady','mizzou','blair', 'baptist',\n",
    "                                                                  'osage','pulaski','marshall','cprb','columbia','morgan','ozark', 'million',\n",
    "                                                                  'mills','grant','texas','police','nevada','news','plains','jefferson',\n",
    "                  'greene','indian','south','region','asset','big','fold','slot','admanager','tncms','render','fixed','ad','four']\n",
    "\n",
    "for i, line in enumerate(civic_document_list): \n",
    "    civic_document_list[i] = ' '.join([x for x in nltk.word_tokenize(line) if (x.lower() not in stop_words) and (x.lower() not in more_stop_words)\n",
    "                                      and not (x.lower().isdigit())])\n",
    "    \n",
    "\n",
    "#Getting bigrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (2,2)) \n",
    "X1 = vectorizer.fit_transform(civic_document_list)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "#print(\"\\n\\nFeatures : \\n\", features) \n",
    "#print(\"\\n\\nX1 : \\n\", X1.toarray()) \n",
    "\n",
    "#Applying TFIDF \n",
    "vectorizer = TfidfVectorizer(ngram_range = (2,2)) \n",
    "X2 = vectorizer.fit_transform(civic_document_list) \n",
    "scores = (X2.toarray()) \n",
    "#print(\"\\n\\nScores : \\n\", scores) \n",
    "\n",
    "#Getting the bigrams \n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "\n",
    "for col, term in enumerate(features): \n",
    "    data1.append((term, sums[0,col])) \n",
    "\n",
    "civic_bigrams = pd.DataFrame(data1, columns = ['term','rank']) \n",
    "\n",
    "civic_bigrams = civic_bigrams.sort_values('rank', ascending=False)\n",
    "civic_bigrams = civic_bigrams[civic_bigrams['term'].str.contains('would|fixed|slot|admanager|region|asset|ad|tncms|logan|news|webster groves|des peres|waynesville')==False ]\n",
    "civic_bigrams.head(60)\n",
    "\n",
    "for x in civic_bigrams['term'].head(10):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planning zoning commission\n",
      "board aldermen meeting\n",
      "short term rentals\n",
      "regular session tuesday\n",
      "city council meeting\n",
      "december meeting tuesday\n",
      "hold december meeting\n",
      "school board hold\n",
      "board hold december\n",
      "county commission met\n"
     ]
    }
   ],
   "source": [
    "#Removing stopwords\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "more_stop_words = ['st.', 'louis', 'kansas', 'p.','m.', 'kmov', 'reserved', 'mo', 'news',\n",
    "                                                                  'correction','typo','email','ky3', 'comcopyright', 'digitalnews', 'fox',\n",
    "                                                                  'springfield', '2022', 'said', 'lady','mizzou','blair', 'baptist',\n",
    "                                                                  'osage','pulaski','marshall','cprb','columbia','morgan','ozark', 'million',\n",
    "                                                                  'mills','grant', 'joplin', 'branson','hill','junction','four']\n",
    "\n",
    "for i, line in enumerate(civic_document_list): \n",
    "    civic_document_list[i] = ' '.join([x for x in nltk.word_tokenize(line) if (x.lower() not in stop_words) and (x.lower() not in more_stop_words)\n",
    "                                      and not (x.lower().isdigit())])\n",
    "    \n",
    "\n",
    "#Getting trigrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (3,3)) \n",
    "X1 = vectorizer.fit_transform(civic_document_list)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "#print(\"\\n\\nFeatures : \\n\", features) \n",
    "#print(\"\\n\\nX1 : \\n\", X1.toarray()) \n",
    "\n",
    "#Applying TFIDF \n",
    "vectorizer = TfidfVectorizer(ngram_range = (3,3)) \n",
    "X2 = vectorizer.fit_transform(civic_document_list) \n",
    "scores = (X2.toarray()) \n",
    "#print(\"\\n\\nScores : \\n\", scores) \n",
    "\n",
    "# Getting the trigrams \n",
    "\n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "\n",
    "for col, term in enumerate(features): \n",
    "    data1.append((term, sums[0,col])) \n",
    "\n",
    "civic_trigrams = pd.DataFrame(data1, columns = ['term','rank']) \n",
    "\n",
    "civic_trigrams = civic_trigrams.sort_values('rank', ascending=False)\n",
    "civic_trigrams = civic_trigrams[civic_trigrams['term'].str.contains('great|asset|rolla|fixed|slot|admanager|region|ad|tncms|logan')==False ]\n",
    "civic_trigrams.head(40)\n",
    "\n",
    "for x in civic_trigrams['term'].head(10):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highway patrol\n",
      "state highway\n",
      "according state\n",
      "vehicle crash\n",
      "crash happened\n",
      "crash report\n",
      "minor injuries\n",
      "happened around\n",
      "investigators say\n",
      "one person\n"
     ]
    }
   ],
   "source": [
    "roads = df2.loc[df2['category'] == 'road']\n",
    "\n",
    "roads_document_list = []\n",
    "for x in roads['text']:\n",
    "    if x not in roads_document_list:\n",
    "        roads_document_list.append(x)\n",
    "    \n",
    "#Removing stopwords\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "more_stop_words = ['st.', 'louis', 'kansas', 'p.','m.', 'kmov', 'reserved', 'mo', 'news',\n",
    "                                                                  'correction','typo','email','ky3', 'comcopyright', 'digitalnews', 'fox',\n",
    "                                                                  'springfield', '2022', 'said', 'lady','mizzou','blair', 'baptist',\n",
    "                                                                  'osage','pulaski','marshall','cprb','columbia','morgan','ozark', 'million',\n",
    "                                                                  'mills','grant', 'missouri', 'u.','s.', 'christian','old','police','please','mercy', 'clay']\n",
    "\n",
    "for i, line in enumerate(roads_document_list): \n",
    "    roads_document_list[i] = ' '.join([x for x in nltk.word_tokenize(line) if (x.lower() not in stop_words) and (x.lower() not in more_stop_words)\n",
    "                                      and not (x.lower().isdigit())])\n",
    "    \n",
    "\n",
    "#Getting bigrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (2,2)) \n",
    "X1 = vectorizer.fit_transform(roads_document_list)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "#print(\"\\n\\nFeatures : \\n\", features) \n",
    "#print(\"\\n\\nX1 : \\n\", X1.toarray()) \n",
    "\n",
    "#Applying TFIDF \n",
    "vectorizer = TfidfVectorizer(ngram_range = (2,2)) \n",
    "X2 = vectorizer.fit_transform(roads_document_list) \n",
    "scores = (X2.toarray()) \n",
    "#print(\"\\n\\nScores : \\n\", scores) \n",
    "\n",
    "#Getting the bigrams \n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "\n",
    "for col, term in enumerate(features): \n",
    "    data1.append((term, sums[0,col])) \n",
    "\n",
    "road_bigrams = pd.DataFrame(data1, columns = ['term','rank']) \n",
    "\n",
    "road_bigrams = road_bigrams.sort_values('rank', ascending=False)\n",
    "road_bigrams = road_bigrams[road_bigrams['term'].str.contains('fixed|slot|admanager|region|ad|tncms|year|kctv|copyright|rights')==False ]\n",
    "road_bigrams.head(75)\n",
    "\n",
    "for x in road_bigrams['term'].head(10):\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state highway patrol\n",
      "according state highway\n",
      "two vehicle crash\n",
      "county according state\n",
      "highway patrol crash\n",
      "crash happened around\n",
      "patrol crash report\n",
      "hospital minor injuries\n",
      "one person died\n",
      "injured two vehicle\n"
     ]
    }
   ],
   "source": [
    "#Removing stopwords\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "more_stop_words = ['st.', 'louis', 'kansas', 'p.','m.', 'kmov', 'reserved', 'mo', 'news',\n",
    "                                                                  'correction','typo','email','ky3', 'comcopyright', 'digitalnews', 'fox',\n",
    "                                                                  'springfield', '2022', 'said', 'lady','mizzou','blair', 'baptist',\n",
    "                                                                  'osage','pulaski','marshall','cprb','columbia','morgan','ozark', 'million',\n",
    "                                                                  'mills','grant', 'missouri', 'u.','s.', 'christian', 'copyright', 'freeman',\n",
    "                                                                  'charles']\n",
    "\n",
    "for i, line in enumerate(roads_document_list): \n",
    "    roads_document_list[i] = ' '.join([x for x in nltk.word_tokenize(line) if (x.lower() not in stop_words) and (x.lower() not in more_stop_words)\n",
    "                                      and not (x.lower().isdigit())])\n",
    "    \n",
    "\n",
    "#Getting trigrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (3,3)) \n",
    "X1 = vectorizer.fit_transform(roads_document_list)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "#print(\"\\n\\nFeatures : \\n\", features) \n",
    "#print(\"\\n\\nX1 : \\n\", X1.toarray()) \n",
    "\n",
    "#Applying TFIDF \n",
    "vectorizer = TfidfVectorizer(ngram_range = (3,3)) \n",
    "X2 = vectorizer.fit_transform(roads_document_list) \n",
    "scores = (X2.toarray()) \n",
    "#print(\"\\n\\nScores : \\n\", scores) \n",
    "\n",
    "#Getting the trigrams \n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "\n",
    "for col, term in enumerate(features): \n",
    "    data1.append((term, sums[0,col])) \n",
    "\n",
    "road_trigrams = pd.DataFrame(data1, columns = ['term','rank']) \n",
    "\n",
    "road_trigrams = road_trigrams.sort_values('rank', ascending=False)\n",
    "road_trigrams = road_trigrams[road_trigrams['term'].str.contains('fixed|slot|admanager|region|ad|tncms|year|kctv|copyright|rights')==False ]\n",
    "road_trigrams.head(40)\n",
    "\n",
    "for x in road_trigrams['term'].head(10):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid 19\n",
      "health care\n",
      "health department\n",
      "mu health\n",
      "sense smell\n",
      "get flu\n",
      "home health\n",
      "emergency department\n",
      "flu shot\n",
      "county health\n"
     ]
    }
   ],
   "source": [
    "health = df2.loc[df2['category'] == 'health']\n",
    "\n",
    "health_document_list = []\n",
    "for x in health['text']:\n",
    "    if x not in health_document_list:\n",
    "        health_document_list.append(x)\n",
    "    \n",
    "#Removing stopwords\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "more_stop_words = ['st.', 'louis', 'kansas', 'p.','m.', 'kmov', 'reserved', 'mo', 'news',\n",
    "                                                                  'correction','typo','email','ky3', 'comcopyright', 'digitalnews', 'fox',\n",
    "                                                                  'springfield', '2022', 'said', 'lady','mizzou','blair', 'baptist',\n",
    "                                                                  'osage','pulaski','marshall','cprb','columbia','morgan','ozark', 'million',\n",
    "                                                                  'mills','grant', 'missouri', 'u.','s.', 'christian', 'beam','a.', '•',\n",
    "                                                                  'ave.','–', 'carter', 'greene','school','barbe', 'spectorsky', 'springfield']\n",
    "\n",
    "for i, line in enumerate(health_document_list): \n",
    "    health_document_list[i] = ' '.join([x for x in nltk.word_tokenize(line) if (x.lower() not in stop_words) and (x.lower() not in more_stop_words)\n",
    "                                      and not (x.lower().isdigit())])\n",
    "    \n",
    "\n",
    "#Getting bigrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (2,2)) \n",
    "X1 = vectorizer.fit_transform(health_document_list)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "#print(\"\\n\\nFeatures : \\n\", features) \n",
    "#print(\"\\n\\nX1 : \\n\", X1.toarray()) \n",
    "\n",
    "#Applying TFIDF \n",
    "vectorizer = TfidfVectorizer(ngram_range = (2,2)) \n",
    "X2 = vectorizer.fit_transform(health_document_list) \n",
    "scores = (X2.toarray()) \n",
    "#print(\"\\n\\nScores : \\n\", scores) \n",
    "\n",
    "#Getting the bigrams \n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "\n",
    "for col, term in enumerate(features): \n",
    "    data1.append((term, sums[0,col])) \n",
    "\n",
    "health_bigrams = pd.DataFrame(data1, columns = ['term','rank']) \n",
    "\n",
    "health_bigrams = health_bigrams.sort_values('rank', ascending=False)\n",
    "health_bigrams = health_bigrams[health_bigrams['term'].str.contains('army|cardinal|washington|greene|phelps|ozarks|fixed|slot|admanager|region|ad|tncms|year|kctv|copyright|rights')==False ]\n",
    "health_bigrams.head(30)\n",
    "\n",
    "for x in health_bigrams['term'].head(10):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu health care\n",
      "community blood center\n",
      "county health department\n",
      "total access urgent\n",
      "covid 19 vaccine\n",
      "home health agency\n",
      "centers disease control\n",
      "access urgent care\n",
      "disease control prevention\n",
      "free covid 19\n"
     ]
    }
   ],
   "source": [
    "#Removing stopwords\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "more_stop_words = ['st.', 'louis', 'kansas', 'p.','m.', 'kmov', 'reserved', 'mo', 'news',\n",
    "                                                                  'correction','typo','email','ky3', 'comcopyright', 'digitalnews', 'fox',\n",
    "                                                                  'springfield', '2022', 'said', 'lady','mizzou','blair', 'baptist',\n",
    "                                                                  'osage','pulaski','marshall','cprb','columbia','morgan','ozark', 'million',\n",
    "                                                                  'mills','grant', 'missouri', 'u.','s.', 'christian', 'beam','a.', '•',\n",
    "                                                                  'ave.','–', 'carter', 'methodist','chestnut','friday', 'noon', 'springfield', 'greene','ozarks']\n",
    "\n",
    "for i, line in enumerate(health_document_list): \n",
    "    health_document_list[i] = ' '.join([x for x in nltk.word_tokenize(line) if (x.lower() not in stop_words) and (x.lower() not in more_stop_words)\n",
    "                                      and not (x.lower().isdigit())])\n",
    "    \n",
    "\n",
    "#Getting trigrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (3,3)) \n",
    "X1 = vectorizer.fit_transform(health_document_list)  \n",
    "features = (vectorizer.get_feature_names()) \n",
    "#print(\"\\n\\nFeatures : \\n\", features) \n",
    "#print(\"\\n\\nX1 : \\n\", X1.toarray()) \n",
    "\n",
    "#Applying TFIDF \n",
    "vectorizer = TfidfVectorizer(ngram_range = (3,3)) \n",
    "X2 = vectorizer.fit_transform(health_document_list) \n",
    "scores = (X2.toarray()) \n",
    "#print(\"\\n\\nScores : \\n\", scores) \n",
    "\n",
    "#Getting the trigrams \n",
    "sums = X2.sum(axis = 0) \n",
    "data1 = [] \n",
    "\n",
    "for col, term in enumerate(features): \n",
    "    data1.append((term, sums[0,col])) \n",
    "\n",
    "health_trigrams = pd.DataFrame(data1, columns = ['term','rank']) \n",
    "\n",
    "health_trigrams = health_trigrams.sort_values('rank', ascending=False)\n",
    "health_trigrams = health_trigrams[health_trigrams['term'].str.contains('army|cardinal|washington|greene|phelps|ozarks|fixed|slot|admanager|region|ad|tncms|year|kctv|copyright|rights')==False ]\n",
    "health_trigrams.head(40)\n",
    "\n",
    "for x in health_trigrams['term'].head(10):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>places</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>The Missouri State Highway Patrol (MSHP) repor...</td>\n",
       "      <td>Route K bonne terre Missouri</td>\n",
       "      <td>-90.555404</td>\n",
       "      <td>37.923107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>92</td>\n",
       "      <td>IRONTON, Mo.  Located in the town of Ironton i...</td>\n",
       "      <td>goulding castle IRONTON missouri</td>\n",
       "      <td>-90.627344</td>\n",
       "      <td>37.597272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>ST. LOUIS, Mo. (KMOV) - All lanes at the Dierb...</td>\n",
       "      <td>dierbergs brentwood missouri</td>\n",
       "      <td>-90.339218</td>\n",
       "      <td>38.627049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Devon Allman says numerology was in his favor ...</td>\n",
       "      <td>the factory chesterfield missouri</td>\n",
       "      <td>-90.592907</td>\n",
       "      <td>38.671848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>There’s still time to map out your New Year’s ...</td>\n",
       "      <td>512 North Euclid Avenue  St. Louis Missouri</td>\n",
       "      <td>-90.260446</td>\n",
       "      <td>38.650053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>ST. LOUIS — An “arctic front” is expected to s...</td>\n",
       "      <td>St. Louis Place  St. Louis Missouri</td>\n",
       "      <td>-90.199404</td>\n",
       "      <td>38.627003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>ST. LOUIS, Mo. (KMOV) - KMOV is partnering wit...</td>\n",
       "      <td>Busch Stadium</td>\n",
       "      <td>-90.192821</td>\n",
       "      <td>38.622619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>CHESTERFIELD — There's little today that draws...</td>\n",
       "      <td>Clarkson Road CHESTERFIELD  Missouri</td>\n",
       "      <td>-90.574280</td>\n",
       "      <td>38.633196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>ST. LOUIS, Mo. (KMOV) - A Metro East man is op...</td>\n",
       "      <td>East alton missouri</td>\n",
       "      <td>-91.831833</td>\n",
       "      <td>37.964253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>(KTTS News) Polk County authorities say a man ...</td>\n",
       "      <td>South 77th Road polk county missouri</td>\n",
       "      <td>-93.488640</td>\n",
       "      <td>37.651384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               text  \\\n",
       "76           76  The Missouri State Highway Patrol (MSHP) repor...   \n",
       "84           92  IRONTON, Mo.  Located in the town of Ironton i...   \n",
       "94           94  ST. LOUIS, Mo. (KMOV) - All lanes at the Dierb...   \n",
       "0             0  Devon Allman says numerology was in his favor ...   \n",
       "93           93  There’s still time to map out your New Year’s ...   \n",
       "..          ...                                                ...   \n",
       "54           54  ST. LOUIS — An “arctic front” is expected to s...   \n",
       "5             5  ST. LOUIS, Mo. (KMOV) - KMOV is partnering wit...   \n",
       "112         112  CHESTERFIELD — There's little today that draws...   \n",
       "166         166  ST. LOUIS, Mo. (KMOV) - A Metro East man is op...   \n",
       "14           14  (KTTS News) Polk County authorities say a man ...   \n",
       "\n",
       "                                          places       long        lat  \n",
       "76                  Route K bonne terre Missouri -90.555404  37.923107  \n",
       "84              goulding castle IRONTON missouri -90.627344  37.597272  \n",
       "94                  dierbergs brentwood missouri -90.339218  38.627049  \n",
       "0              the factory chesterfield missouri -90.592907  38.671848  \n",
       "93   512 North Euclid Avenue  St. Louis Missouri -90.260446  38.650053  \n",
       "..                                           ...        ...        ...  \n",
       "54           St. Louis Place  St. Louis Missouri -90.199404  38.627003  \n",
       "5                                  Busch Stadium -90.192821  38.622619  \n",
       "112         Clarkson Road CHESTERFIELD  Missouri -90.574280  38.633196  \n",
       "166                          East alton missouri -91.831833  37.964253  \n",
       "14          South 77th Road polk county missouri -93.488640  37.651384  \n",
       "\n",
       "[960 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing data set\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "files = glob.glob(\"/home/mazz76/jupyter/Civic_Info_Project/Unseen Test Data for TFIDF Bigrams/*.csv\")\n",
    "\n",
    "test_data = []\n",
    "for f in files:\n",
    "    csv = pd.read_csv(f)\n",
    "    test_data.append(csv)\n",
    "testing_data = pd.concat(test_data)\n",
    "\n",
    "testing_data\n",
    "\n",
    "#Shuffle Rows\n",
    "\n",
    "testing_data = testing_data.sample(frac=1)\n",
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "#Getting a list with the cleaned text (free of stopwords)\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "text_data = []\n",
    "for x in testing_data['text']:\n",
    "    text_data.append(x)\n",
    "\n",
    "cleaned_text = []\n",
    "for x in text_data:\n",
    "    tokens = word_tokenize(x)\n",
    "    tokens_wo_stopwords = [word for word in tokens if word.lower() not in stop_words and not word.lower().isdigit()]\n",
    "    cleaned_text.append(tokens_wo_stopwords)\n",
    "    \n",
    "cleaned_text_final = []\n",
    "for x in cleaned_text:\n",
    "    y = \" \".join(x)\n",
    "    cleaned_text_final.append(y.lower())\n",
    "\n",
    "\n",
    "cleaned_text_final\n",
    "\n",
    "#Inserting data back into dataframe\n",
    "testing_data['text'] = cleaned_text_final\n",
    "testing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now getting the list of all of the bigrams from above\n",
    "crime_bigrams_list = []\n",
    "for x in crime_bigrams['term'].head(500):\n",
    "    crime_bigrams_list.append(x.lower())\n",
    "    \n",
    "sports_bigrams_list = []\n",
    "for x in sports_bigrams['term'].head(500):\n",
    "    sports_bigrams_list.append(x.lower())\n",
    "    \n",
    "roads_bigrams_list = []\n",
    "for x in road_bigrams['term'].head(500):\n",
    "    roads_bigrams_list.append(x.lower())\n",
    "\n",
    "civic_bigrams_list = []\n",
    "for x in civic_bigrams['term'].head(500):\n",
    "    civic_bigrams_list.append(x.lower())\n",
    "    \n",
    "health_bigrams_list = []\n",
    "for x in health_bigrams['term'].head(500):\n",
    "    health_bigrams_list.append(x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will tally how many of each of the top bigrams appear in each news article. The category with the most\n",
    "#bigrams will be the article's classification\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def f(cell_value):\n",
    "    return [((v[1])) for v in ((s, cell_value.count(s)) for s in search) if v]\n",
    "\n",
    "search = crime_bigrams_list\n",
    "df=testing_data['text'].apply(f)\n",
    "\n",
    "search = sports_bigrams_list\n",
    "df1=testing_data['text'].apply(f)\n",
    "\n",
    "search = roads_bigrams_list\n",
    "df2=testing_data['text'].apply(f)\n",
    "\n",
    "search = civic_bigrams_list\n",
    "df3=testing_data['text'].apply(f)\n",
    "\n",
    "search = health_bigrams_list\n",
    "df4=testing_data['text'].apply(f)\n",
    "\n",
    "df5 = pd.DataFrame({'text': testing_data['text'], 'num_crime_bigrams': df.apply(np.count_nonzero), 'num_sports_bigrams': df1.apply(np.count_nonzero), \n",
    "                    'num_roads_bigrams': df2.apply(np.count_nonzero), 'num_civic_bigrams': df3.apply(np.count_nonzero), \n",
    "                    'num_health_bigrams': df4.apply(np.count_nonzero)})\n",
    "\n",
    "#Next find the \"winner\" category by finding the category with the maximum number of bigrams\n",
    "df5['bigram_winner'] = np.where(df5.loc[:, df5.columns != 'text'].eq(df5.loc[:, df5.columns != 'text'].max(axis=1), axis=0).sum(axis=1) > 1,\n",
    "                        'other', \n",
    "                         df5.loc[:, df5.columns != 'text'].idxmax(axis=1))\n",
    "\n",
    "\n",
    "df5['bigram_winner'] = df5['bigram_winner'].str.replace('num_', '')\n",
    "df5['bigram_winner'] = df5['bigram_winner'].str.replace('_bigrams', '')\n",
    "\n",
    "df5\n",
    "\n",
    "#Drop the duplicates\n",
    "df5.drop_duplicates(subset=['text'], inplace=True)\n",
    "df5\n",
    "df5.to_csv('bigram_testing_1000_terms.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the list of all of the trigrams from above\n",
    "crime_trigrams_list = []\n",
    "for x in crime_trigrams['term'].head(50):\n",
    "    crime_trigrams_list.append(x.lower())\n",
    "    \n",
    "sports_trigrams_list = []\n",
    "for x in sports_trigrams['term'].head(50):\n",
    "    sports_trigrams_list.append(x.lower())\n",
    "    \n",
    "roads_trigrams_list = []\n",
    "for x in road_trigrams['term'].head(50):\n",
    "    roads_trigrams_list.append(x.lower())\n",
    "\n",
    "civic_trigrams_list = []\n",
    "for x in civic_trigrams['term'].head(50):\n",
    "    civic_trigrams_list.append(x.lower())\n",
    "    \n",
    "health_trigrams_list = []\n",
    "for x in health_trigrams['term'].head(50):\n",
    "    health_trigrams_list.append(x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(cell_value):\n",
    "    return [((v[1])) for v in ((s, cell_value.count(s)) for s in search) if v]\n",
    "\n",
    "search = crime_trigrams_list\n",
    "df=testing_data['text'].apply(f)\n",
    "\n",
    "search = sports_trigrams_list\n",
    "df1=testing_data['text'].apply(f)\n",
    "\n",
    "search = roads_trigrams_list\n",
    "df2=testing_data['text'].apply(f)\n",
    "\n",
    "search = civic_trigrams_list\n",
    "df3=testing_data['text'].apply(f)\n",
    "\n",
    "search = health_trigrams_list\n",
    "df4=testing_data['text'].apply(f)\n",
    "\n",
    "df5 = pd.DataFrame({'text': testing_data['text'], 'num_crime_trigrams': df.apply(np.count_nonzero), 'num_sports_trigrams': df1.apply(np.count_nonzero), \n",
    "                    'num_roads_trigrams': df2.apply(np.count_nonzero), 'num_civic_trigrams': df3.apply(np.count_nonzero), \n",
    "                    'num_health_trigrams': df4.apply(np.count_nonzero)})\n",
    "\n",
    "#Next find the \"winner\" category by finding the category with the maximum number of bigrams\n",
    "df5['trigram_winner'] = np.where(df5.loc[:, df5.columns != 'text'].eq(df5.loc[:, df5.columns != 'text'].max(axis=1), axis=0).sum(axis=1) > 1,\n",
    "                        'Unknown', \n",
    "                         df5.loc[:, df5.columns != 'text'].idxmax(axis=1))\n",
    "\n",
    "df5['trigram_winner'] = df5['trigram_winner'].str.replace('num_', '')\n",
    "df5['trigram_winner'] = df5['trigram_winner'].str.replace('_trigrams', '')\n",
    "\n",
    "#Drop the duplicates\n",
    "df5.drop_duplicates(subset=['text'], inplace=True)\n",
    "df5.to_csv('trigram_testing_data_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
